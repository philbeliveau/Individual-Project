{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e3fa1f",
   "metadata": {},
   "source": [
    "# Week 1 Read the resources\n",
    "\n",
    "1. Understanding of the problem/ Research/Hypothesis \n",
    "2. Get the data/\n",
    "Where is it/\n",
    "Can you process it? \n",
    "\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98de38",
   "metadata": {},
   "source": [
    "### Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9c12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import pandas as pd \n",
    "import seaborn as sns; sns.set()\n",
    "# Chart drawing\n",
    "import plotly as py\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf3e4a",
   "metadata": {},
   "source": [
    "## 1. Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8126be",
   "metadata": {},
   "source": [
    "### Download and Prepare PHM08 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3244c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/philippebeliveau/Desktop/BSTA 478/Projet/creditcard.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0190e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data set between features and target\n",
    "features=df.drop(['Class'], axis=1)\n",
    "target = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2fbf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df=pd.DataFrame(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fffc45",
   "metadata": {},
   "source": [
    "Information about the dataset: \n",
    "\n",
    " The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9904dfc",
   "metadata": {},
   "source": [
    "What does the columns represent:\n",
    "\n",
    "PCA features\n",
    "This new array has the same number of rows and columns as the original sample array. In particular, there is one row for each transformed sample. The columns of the new array correspond to \"PCA features\", just as the original features corresponded to columns of the original array.\n",
    "\n",
    "PCA features are not correlated\n",
    "It is often the case that the features of a dataset are correlated. This is the case with many of the features of the wine dataset, for instance. However, PCA, due to the rotation it performs, \"de-correlates\" the data, in the sense that the columns of the transformed array are not linearly correlated.!\n",
    "\n",
    "So those columns are those PCA features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1cbe5",
   "metadata": {},
   "source": [
    "# Week 2 Perform EDA\n",
    "2. Data cleaning: \n",
    "Define standards, drop columns, missing values, feature engineering \n",
    "    \n",
    "3. Data visualization  (EDA): Derived insight from the data and engine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe62966",
   "metadata": {},
   "source": [
    "## 1. Data cleaning\n",
    "### 2.1 Define standards, drop columns, missing values, feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba56489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.481386e+04</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.772925e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.289524e-16</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.803266e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.674888e-15</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.475621e-15</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.501098e-15</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.392460e-15</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-7.466538e-16</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.258754e-16</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.019919e-16</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.126845e-16</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.834962e+01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std         min           25%  \\\n",
       "Time    284807.0  9.481386e+04  47488.145955    0.000000  54201.500000   \n",
       "V1      284807.0  3.918649e-15      1.958696  -56.407510     -0.920373   \n",
       "V2      284807.0  5.682686e-16      1.651309  -72.715728     -0.598550   \n",
       "V3      284807.0 -8.761736e-15      1.516255  -48.325589     -0.890365   \n",
       "V4      284807.0  2.811118e-15      1.415869   -5.683171     -0.848640   \n",
       "V5      284807.0 -1.552103e-15      1.380247 -113.743307     -0.691597   \n",
       "V6      284807.0  2.040130e-15      1.332271  -26.160506     -0.768296   \n",
       "V7      284807.0 -1.698953e-15      1.237094  -43.557242     -0.554076   \n",
       "V8      284807.0 -1.893285e-16      1.194353  -73.216718     -0.208630   \n",
       "V9      284807.0 -3.147640e-15      1.098632  -13.434066     -0.643098   \n",
       "V10     284807.0  1.772925e-15      1.088850  -24.588262     -0.535426   \n",
       "V11     284807.0  9.289524e-16      1.020713   -4.797473     -0.762494   \n",
       "V12     284807.0 -1.803266e-15      0.999201  -18.683715     -0.405571   \n",
       "V13     284807.0  1.674888e-15      0.995274   -5.791881     -0.648539   \n",
       "V14     284807.0  1.475621e-15      0.958596  -19.214325     -0.425574   \n",
       "V15     284807.0  3.501098e-15      0.915316   -4.498945     -0.582884   \n",
       "V16     284807.0  1.392460e-15      0.876253  -14.129855     -0.468037   \n",
       "V17     284807.0 -7.466538e-16      0.849337  -25.162799     -0.483748   \n",
       "V18     284807.0  4.258754e-16      0.838176   -9.498746     -0.498850   \n",
       "V19     284807.0  9.019919e-16      0.814041   -7.213527     -0.456299   \n",
       "V20     284807.0  5.126845e-16      0.770925  -54.497720     -0.211721   \n",
       "V21     284807.0  1.473120e-16      0.734524  -34.830382     -0.228395   \n",
       "V22     284807.0  8.042109e-16      0.725702  -10.933144     -0.542350   \n",
       "V23     284807.0  5.282512e-16      0.624460  -44.807735     -0.161846   \n",
       "V24     284807.0  4.456271e-15      0.605647   -2.836627     -0.354586   \n",
       "V25     284807.0  1.426896e-15      0.521278  -10.295397     -0.317145   \n",
       "V26     284807.0  1.701640e-15      0.482227   -2.604551     -0.326984   \n",
       "V27     284807.0 -3.662252e-16      0.403632  -22.565679     -0.070840   \n",
       "V28     284807.0 -1.217809e-16      0.330083  -15.430084     -0.052960   \n",
       "Amount  284807.0  8.834962e+01    250.120109    0.000000      5.600000   \n",
       "Class   284807.0  1.727486e-03      0.041527    0.000000      0.000000   \n",
       "\n",
       "                 50%            75%            max  \n",
       "Time    84692.000000  139320.500000  172792.000000  \n",
       "V1          0.018109       1.315642       2.454930  \n",
       "V2          0.065486       0.803724      22.057729  \n",
       "V3          0.179846       1.027196       9.382558  \n",
       "V4         -0.019847       0.743341      16.875344  \n",
       "V5         -0.054336       0.611926      34.801666  \n",
       "V6         -0.274187       0.398565      73.301626  \n",
       "V7          0.040103       0.570436     120.589494  \n",
       "V8          0.022358       0.327346      20.007208  \n",
       "V9         -0.051429       0.597139      15.594995  \n",
       "V10        -0.092917       0.453923      23.745136  \n",
       "V11        -0.032757       0.739593      12.018913  \n",
       "V12         0.140033       0.618238       7.848392  \n",
       "V13        -0.013568       0.662505       7.126883  \n",
       "V14         0.050601       0.493150      10.526766  \n",
       "V15         0.048072       0.648821       8.877742  \n",
       "V16         0.066413       0.523296      17.315112  \n",
       "V17        -0.065676       0.399675       9.253526  \n",
       "V18        -0.003636       0.500807       5.041069  \n",
       "V19         0.003735       0.458949       5.591971  \n",
       "V20        -0.062481       0.133041      39.420904  \n",
       "V21        -0.029450       0.186377      27.202839  \n",
       "V22         0.006782       0.528554      10.503090  \n",
       "V23        -0.011193       0.147642      22.528412  \n",
       "V24         0.040976       0.439527       4.584549  \n",
       "V25         0.016594       0.350716       7.519589  \n",
       "V26        -0.052139       0.240952       3.517346  \n",
       "V27         0.001342       0.091045      31.612198  \n",
       "V28         0.011244       0.078280      33.847808  \n",
       "Amount     22.000000      77.165000   25691.160000  \n",
       "Class       0.000000       0.000000       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ddf6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 284807 rows\n",
      "The dataframe has 31 columns\n"
     ]
    }
   ],
   "source": [
    "print('The dataframe has {} rows'.format(df.shape[0]))\n",
    "print('The dataframe has {} columns'.format(df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e93c32d",
   "metadata": {},
   "source": [
    "### Missing Values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278e90e",
   "metadata": {},
   "source": [
    "Make sure that our dataset does not possess any NaN values, and give some explanantion about what would this entails if we had some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf403ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for NA values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8af1e",
   "metadata": {},
   "source": [
    "After having clean missing value, we are now left with this DataFrame to perform our EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f37f7",
   "metadata": {},
   "source": [
    "## Balance Dataset = No need for autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac8a1c",
   "metadata": {},
   "source": [
    "## Conclusion of EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question to ask: \n",
    "# are we including the settings names?\n",
    "# So what are we face off? \n",
    "# What else could I add in my EDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b7f3c",
   "metadata": {},
   "source": [
    "# Week 3 (19 – 5 march)  Perform the data preparation \n",
    "4. Data partitioning \n",
    "5. Data preparation \n",
    "6. Scaling\n",
    "6. Feature selection and creation \n",
    "4. Test of Stationarity for all features\n",
    "4. Lag values + AR + MA terms \n",
    "4. Multicollinearity\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b0ae1",
   "metadata": {},
   "source": [
    "## 1. Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344cca97",
   "metadata": {},
   "source": [
    "### Data partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc89cd",
   "metadata": {},
   "source": [
    "It is now important to drop the columnns that are insignificant or that are literaly giving the information about the Remaining useful life. Think about it, when a new engine is functioning, what information do we have about it, we can't have the max cycles that he reached, because he is still running.\n",
    "\n",
    "And, we can't give him our model the RUL, because this is what we are trying to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36398b",
   "metadata": {},
   "source": [
    "### 2. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c89a32",
   "metadata": {},
   "source": [
    "Question: \n",
    "\n",
    "Why scaling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9454fb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philippebeliveau/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning:\n",
      "\n",
      "`np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array(features).astype(np.float)\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "X_scaled=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c6f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_df = pd.DataFrame(X_scaled)\n",
    "target_df = pd.DataFrame(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec77ef0",
   "metadata": {},
   "source": [
    "### 3. Feature selection and creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ff603",
   "metadata": {},
   "source": [
    "### 4. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600fde1",
   "metadata": {},
   "source": [
    "#### Benchmark model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483d1ae",
   "metadata": {},
   "source": [
    "#### Reduce number of features down to the one selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cda1f7",
   "metadata": {},
   "source": [
    "## Week 4 (5 march – 19 march) Algorithm\n",
    "7.Data format to enter in the algorithm (This will change given the algorithm) \n",
    "\n",
    "8.Implementation of the algorithms/ Which one to use? /hyperparameter tuning (Grid search) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4624499a",
   "metadata": {},
   "source": [
    "# Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc20308c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227845, 1)\n",
      "(56962, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, target_df\n",
    "                                                    , test_size=0.2\n",
    "                                                    , random_state=42)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac67a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://trenton3983.github.io/files/projects/2019-07-19_fraud_detection_python/2019-07-19_fraud_detection_python.html\n",
    "\n",
    "def get_model_results(X_train: np.ndarray, y_train: np.ndarray,\n",
    "                      X_test: np.ndarray, y_test: np.ndarray, model, max_iter = 1000000):\n",
    "    \"\"\"\n",
    "    model: sklearn model (e.g. RandomForestClassifier)\n",
    "    \"\"\"\n",
    "    # Fit your training model to your training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Obtain the predicted values and probabilities from the model \n",
    "    predicted = model.predict(X_test)\n",
    "    \n",
    "    try:\n",
    "        probs = model.predict_proba(X_test)\n",
    "        print('ROC Score:')\n",
    "        print(roc_auc_score(y_test, probs[:,1]))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    # Print the ROC curve, classification report and confusion matrix\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72773fbb",
   "metadata": {},
   "source": [
    "#### Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b054feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72de0f85",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philippebeliveau/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/Users/philippebeliveau/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dk/39_21_r51vg7j_fkt5p1mh5r0000gn/T/ipykernel_13853/3634363551.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mensemble_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'rf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'dt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Get the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mget_model_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/dk/39_21_r51vg7j_fkt5p1mh5r0000gn/T/ipykernel_13853/2222124292.py\u001b[0m in \u001b[0;36mget_model_results\u001b[0;34m(X_train, y_train, X_test, y_test, model, max_iter)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Fit your training model to your training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Obtain the predicted values and probabilities from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             )\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"drop\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the three classifiers to use in the ensemble\n",
    "clf1 = LogisticRegression(random_state=5)\n",
    "clf2 = RandomForestClassifier(criterion='gini', max_depth=8, max_features='log2',\n",
    "            min_samples_leaf=10, n_estimators=30, n_jobs=1, random_state=5)\n",
    "clf3 = DecisionTreeClassifier(random_state=5)\n",
    "# Combine the classifiers in the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='hard')\n",
    "# Get the results \n",
    "get_model_results(X_train, y_train, X_test, y_test, ensemble_model, max_iter = 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dae8c8",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a819efd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features='log2', min_samples_leaf=8,\n",
       "                       n_jobs=1, random_state=42)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(criterion='gini', max_depth=10, max_features='log2',\n",
    "            min_samples_leaf=8, n_estimators=100, n_jobs=1, random_state=42)\n",
    "\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f241dad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999685820105722\n"
     ]
    }
   ],
   "source": [
    "# Predict \n",
    "\n",
    "predicted = clf2.predict(X_test)\n",
    "probs = clf2.predict_proba(X_test)\n",
    "print(roc_auc_score(y_test, probs[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e68b83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906090076147934"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score\n",
    "clf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc1161b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     56750\n",
      "           1       1.00      0.98      0.99     56976\n",
      "\n",
      "    accuracy                           0.99    113726\n",
      "   macro avg       0.99      0.99      0.99    113726\n",
      "weighted avg       0.99      0.99      0.99    113726\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56673    77]\n",
      " [  991 55985]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dee707",
   "metadata": {},
   "source": [
    "#### How does our model perform on non-resample dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7058f0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philippebeliveau/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning:\n",
      "\n",
      "X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    284315\n",
      "           1       0.05      0.78      0.09       492\n",
      "\n",
      "    accuracy                           0.97    284807\n",
      "   macro avg       0.52      0.87      0.54    284807\n",
      "weighted avg       1.00      0.97      0.98    284807\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[276444   7871]\n",
      " [   110    382]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "no_resampled_predict = clf2.predict(features)\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(target, no_resampled_predict))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(target, no_resampled_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "79aca3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of the fraud is 15252\n",
      "From the fraud that have been correclty predicted fraud 25.049180327868854 %\n"
     ]
    }
   ],
   "source": [
    "print('sum of the fraud is {}'.format(df[df['Class']==1].count().sum()))\n",
    "print('From the fraud that have been correclty predicted fraud', (382/1525)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb2646d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.00172749 0.0462862  1.        ]\n",
      "Recall: [1.         0.77642276 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Obtain precision and recall\n",
    "precision, recall, _ = precision_recall_curve(target, no_resampled_predict)\n",
    "print(f'Precision: {precision}\\nRecall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7b241e",
   "metadata": {},
   "source": [
    "## Interpretation of Classification Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe06586c",
   "metadata": {},
   "source": [
    "We see that our model hasn't been able to well classify the fraud from the non-fraud, as the precision is 5% \n",
    "\n",
    "Now the question should be how to minimize the False Positive rate (False Positive is: The model predict that it is not a fraud, but in fact it is.) We want to maximize the True negative, meaning we predict it's a fraud, while it is actually a fraud. The negative represents fraud (1) and positive non-fraud (0). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a484fd",
   "metadata": {},
   "source": [
    "### Conclusion on Tree\n",
    "\n",
    "Those model are clearly not good enough for this task, even tho we could look for hyperparameter tuning, we seem to be overfitting with the resampled data with whatever I tried and it performs really badly when apply on the non-resampled set. \n",
    "\n",
    "Although, because the non-resampled set is not being scale and the dataset that we trained on is scale, it might have an impact. I should confirm this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec51368",
   "metadata": {},
   "source": [
    "## Autoencoders\n",
    "\n",
    "https://towardsdatascience.com/applying-anomaly-detection-with-autoencoders-to-fraud-detection-feaaee6b5b09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b8af3",
   "metadata": {},
   "source": [
    "The Autoencoder will encode our data into a subspace and decode the feature back while normalizing the data. Our expectation is autoencoder will learn the features of normal transactions and the input will be similar to output when applied. \n",
    "\n",
    "For anomalies, the input and the output will be significantly different since it is unexpected data.\n",
    "\n",
    "\n",
    "The good part of this approach is it allows us to use unsupervised learning and we usually have plenty of normal transaction data. Data labeling is usually expensive, hard, and in some cases unavailable. Manual data labeling also includes human interaction which causes human biased implementations. It can be seen that in the model training we only use normal transaction features and not the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a81292",
   "metadata": {},
   "source": [
    "## Why AE and what questions to ask\n",
    "\n",
    "What will be our input? \n",
    "\n",
    "What does represent our latent layer? \n",
    "\n",
    "What will represent our output? \n",
    "\n",
    "How to define the nodes? \n",
    "\n",
    "What is the idea of a threshold to detect anomalies? \n",
    "\n",
    "The idea behind the application of an autoencoders in the context of fraud prediction is that we will give as inputs the transactions, we hope to learn the features of the normal transactions in the encoder, we flatten the information in a flatten layer, making the latent space. Then, we hope that the decoder recreates the observations as normal transaction. Then when the decoder transform back the observations as if they were non-fraud observations. Given those reconstructed observations that are supposedly non-fraud observations, we can now see which observations have big loss function. Those will potentially be our fraud case. \n",
    "\n",
    "I believe autoencoders will be really useful for this task as we have very few fraud transactions, which gives the opportunity to the encoder in learning the normal transactions features and patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1fa9eb",
   "metadata": {},
   "source": [
    "### 1. Data format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396bdda",
   "metadata": {},
   "source": [
    "# Narrative\n",
    "\n",
    "We have to train our model on the normal transactions and give the anomaly to predict to the AE. Then, we will look at the prediction of the AE and see if there is a large disruption between the actual value \n",
    "and the predicted value. If there is a big difference, we might flag this transaction as an anomaly. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa3d3ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philippebeliveau/anaconda3/envs/TFT_Tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning:\n",
      "\n",
      "`np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of non_fraud (284315, 30)\n",
      "Shape of fraud (492, 30)\n"
     ]
    }
   ],
   "source": [
    "# So let's build the normal and anomaly data. \n",
    "\n",
    "# Dataframe\n",
    "y = np.array(target_df).astype(np.float)\n",
    "df_input = pd.concat([pd.DataFrame(X_scaled), pd.DataFrame({'Y_Fraud_N':y.flatten()})], axis=1)\n",
    "\n",
    "df_non_fraud= df_input[df_input['Y_Fraud_N']==0]\n",
    "df_fraud = df_input[df_input['Y_Fraud_N']==1]\n",
    "\n",
    "# Take off the Y_Fraud_N variable \n",
    "\n",
    "df_non_fraud = df_non_fraud.drop('Y_Fraud_N', axis=1)\n",
    "df_fraud = df_fraud.drop('Y_Fraud_N', axis=1)\n",
    "\n",
    "print('Shape of non_fraud {}'.format(df_non_fraud.shape))\n",
    "\n",
    "print('Shape of fraud {}'.format(df_fraud.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86fa095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df_non_fraud, test_size=0.2)\n",
    "\n",
    "n_features= df_non_fraud.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ee855",
   "metadata": {},
   "source": [
    "### 2. Implementation of the algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5b7bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets, decomposition, preprocessing, model_selection\n",
    "from keras import models, layers, activations, losses, optimizers, metrics\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf23ae4",
   "metadata": {},
   "source": [
    "dataset_seed : Random seed for shuffling dataset\n",
    "\n",
    "scale : % of the dataset to use (1. for 100%)\n",
    "\n",
    "latent_dim : Dimension of the latent space\n",
    "\n",
    "train_prop : Percentage for train (the rest being for the test)\n",
    "\n",
    "batch_size : Batch sizeepochs : Nb of epochs for training\\\n",
    "\n",
    "fit_verbosity is the verbosity during training : 0 = silent, 1 = progress bar, 2 = one line per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "665000c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_seed     = 123\n",
    "\n",
    "scale            = 1\n",
    "\n",
    "latent_dim       = 10\n",
    "\n",
    "train_prop       = .8\n",
    "batch_size       = 128\n",
    "epochs           = 30\n",
    "fit_verbosity    = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e015dd58",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed30bc15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 13:27:03.918200: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "encoder = models.Sequential(name='encoder')\n",
    "encoder.add(layer=layers.Dense(units=30, activation=activations.relu, input_shape=[n_features]))\n",
    "encoder.add(layers.Dropout(0.1))\n",
    "encoder.add(layer=layers.Dense(units=15, activation=activations.relu))\n",
    "encoder.add(layer=layers.Dense(units=5, activation=activations.relu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd545c",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3213a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = models.Sequential(name='decoder')\n",
    "decoder.add(layer=layers.Dense(units=15, activation=activations.relu, input_shape=[5]))\n",
    "decoder.add(layer=layers.Dense(units=30, activation=activations.relu))\n",
    "decoder.add(layers.Dropout(0.1))\n",
    "decoder.add(layer=layers.Dense(units=n_features, activation=activations.sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a49fdd",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5affb872",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = models.Sequential([encoder, decoder])\n",
    "\n",
    "autoencoder.compile(\n",
    "loss=losses.MSE,\n",
    "optimizer=tf.optimizers.SGD(),\n",
    "metrics=[metrics.mean_squared_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfda2159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd593bd1a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd593bd1a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7057/7108 [============================>.] - ETA: 0s - loss: 0.0226 - mean_squared_error: 0.0226WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd593472b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd593472b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7108/7108 [==============================] - 9s 1ms/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
      "Epoch 2/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 3/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 4/100\n",
      "7108/7108 [==============================] - 7s 999us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 5/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 6/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 7/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 8/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 9/100\n",
      "7108/7108 [==============================] - 9s 1ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 10/100\n",
      "7108/7108 [==============================] - 9s 1ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 11/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 12/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 13/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 14/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 15/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 16/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 17/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 18/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 19/100\n",
      "7108/7108 [==============================] - 9s 1ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 20/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 21/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 22/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 23/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 24/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 25/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 26/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 27/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 28/100\n",
      "7108/7108 [==============================] - 7s 998us/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 29/100\n",
      "7108/7108 [==============================] - 7s 962us/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 30/100\n",
      "7108/7108 [==============================] - 7s 960us/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 31/100\n",
      "7108/7108 [==============================] - 7s 946us/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 32/100\n",
      "7108/7108 [==============================] - 7s 940us/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 33/100\n",
      "7108/7108 [==============================] - 7s 956us/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 34/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 35/100\n",
      "7108/7108 [==============================] - 10s 1ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 36/100\n",
      "7108/7108 [==============================] - 7s 990us/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 37/100\n",
      "7108/7108 [==============================] - 9s 1ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 38/100\n",
      "7108/7108 [==============================] - 9s 1ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "7108/7108 [==============================] - 7s 958us/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 40/100\n",
      "7108/7108 [==============================] - 7s 958us/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 41/100\n",
      "7108/7108 [==============================] - 7s 966us/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 42/100\n",
      "7108/7108 [==============================] - 7s 936us/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 43/100\n",
      "7108/7108 [==============================] - 7s 968us/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 44/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 45/100\n",
      "7108/7108 [==============================] - 7s 952us/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 46/100\n",
      "7108/7108 [==============================] - 7s 963us/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 47/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 48/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 49/100\n",
      "7108/7108 [==============================] - 7s 953us/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 50/100\n",
      "7108/7108 [==============================] - 7s 970us/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 51/100\n",
      "7108/7108 [==============================] - 7s 964us/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 52/100\n",
      "7108/7108 [==============================] - 7s 966us/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 53/100\n",
      "7108/7108 [==============================] - 7s 983us/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 54/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 55/100\n",
      "7108/7108 [==============================] - 7s 969us/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 56/100\n",
      "7108/7108 [==============================] - 7s 985us/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 57/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 58/100\n",
      "7108/7108 [==============================] - 7s 969us/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 59/100\n",
      "7108/7108 [==============================] - 7s 949us/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 60/100\n",
      "7108/7108 [==============================] - 7s 962us/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 61/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 62/100\n",
      "7108/7108 [==============================] - 7s 958us/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 63/100\n",
      "7108/7108 [==============================] - 7s 946us/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 64/100\n",
      "7108/7108 [==============================] - 7s 970us/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 65/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 66/100\n",
      "7108/7108 [==============================] - 7s 957us/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 67/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 68/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 69/100\n",
      "7108/7108 [==============================] - 9s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 70/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 71/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 72/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 73/100\n",
      "7108/7108 [==============================] - 9s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 74/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 75/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 76/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 77/100\n",
      "7108/7108 [==============================] - 7s 937us/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 78/100\n",
      "7108/7108 [==============================] - 7s 952us/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 79/100\n",
      "7108/7108 [==============================] - 7s 947us/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 80/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 81/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 82/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 83/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 84/100\n",
      "7108/7108 [==============================] - 9s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 85/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 86/100\n",
      "7108/7108 [==============================] - 8s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 87/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7108/7108 [==============================] - 7s 966us/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 89/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 90/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 91/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 92/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 93/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 94/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 95/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 96/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 97/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 98/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 99/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 100/100\n",
      "7108/7108 [==============================] - 7s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEXCAYAAACDChKsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1I0lEQVR4nO3deXRUZYI28OcutaRSlVSWSgJhExBQQFDpFkFAW49sidhptMEFXFql21Ebv0YRUUdlURsbvqHV9muXdsalYQ4emDgIONoOKKgtyiagoEBCCNn3Wm/d9/vjJpUUSaBSpEhIPb9z6qTuUlXvS0KevMt9rySEECAiIuoguasLQERE5ycGCBERRYUBQkREUWGAEBFRVBggREQUFQYIERFFhQFC1Oj48eMYOnQobrvttlbHFi5ciKFDh6KysrJD73nffffh/fffP+05X375JXJyctosz6WXXtqhzyM6lxggRC1YLBYcOXIERUVFoX1utxvffPNNF5aKqHtSu7oARN2JoiiYOnUq8vPzMW/ePADAli1bcO211+KNN94InbdmzRr8x3/8B2RZRnp6Op544glccMEFKCkpwcKFC1FaWorevXujoqIi9Joff/wRS5cuRXV1NYLBIG6//XbMnDkzqnLW1dXh6aefxsGDByFJEiZMmICHH34Yqqri3/7t3/DRRx/BZDIhJSUFy5cvR0ZGRrv7iaImiEgIIURhYaEYPXq02Lt3r5gyZUpo/9y5c8X3338vhgwZIioqKsT27dvFddddJyoqKoQQQqxbt05MnTpV6Loufve734mVK1cKIYQ4evSoGD16tFi3bp0IBAJi2rRpYt++fUIIIWpra8XUqVPFt99+K7744gsxffr0dsvTlkceeUQ8++yzQtd14fP5xF133SVeffVVceLECXHZZZcJn88nhBDi9ddfFx999FG7+4nOBlsgRKcYMWIEFEXBvn37kJaWhoaGBgwZMiR0fNu2bZg2bRpSU1MBAHl5eVi6dCmOHz+O7du349FHHwUA9O/fH1dccQUA4OjRoygoKMCiRYtC7+P1erF//34MGjSow2XcunUr3nvvPUiSBLPZjFmzZuGtt97Cb37zGwwbNgy//OUvMXHiREycOBFXXnkldF1vcz/R2WCAELXhhhtuwH/9138hNTUVM2bMCDum63qr84UQ0DQNkiRBtFheTlWN/2LBYBAOhwMbNmwIHSsvL4fD4cCuXbs6XD5d1yFJUti2pmmQZRlvv/029u7dix07dmDZsmWYMGECHnnkkXb3E0WLg+hEbZgxYwY2bdqEjRs3tpohNWHCBGzcuDE0I2vdunVwOp3o378/JkyYgDVr1gAATpw4gS+//BIAcMEFF8BqtYYCpLi4GDk5Odi3b19U5bvqqqvw9ttvQwgBv9+PtWvXYty4cTh48CBycnIwaNAg3Hfffbjjjjuwd+/edvcTnQ22QIjakJmZiUGDBsHhcMDpdIYdGz9+PO644w7MnTsXuq4jNTUVr776KmRZxlNPPYXHHnsMU6dORVZWFoYNGwYAMJvNePnll7F06VK89tpr0DQNDz30EC6//PJQyLTF7Xa3msr797//HYsXL8aSJUuQm5uLQCCACRMmYN68eTCbzZg6dSp+9atfwWazwWq1YvHixRg2bFib+4nOhiQEl3MnIqKOYxcWERFFhQFCRERRYYAQEVFUGCBERBQVBggREUWFAUJERFGJq+tAqqoaoOvRzVpOS7OjoqK+k0vUvcVjnYH4rDfrHD86Um9ZlpCSktju8bgKEF0XUQdI0+vjTTzWGYjPerPO8aOz6s0uLCIiigoDhIiIohJXXVhtEUKgqqoMfr8XQPvNutJSuc1VWM9fEsxmK1JSXGGruhIRRSruA6S+vgaSJCEzsw8kqf0GmarK0LSeEyBC6KiuLkd9fQ0cDmdXF4eIzkNx34Xl8dTD4XCeNjx6IkmS4XCkwOOJv1koRNQ54uu3Zht0PQhFic+GmKKo0PVgVxeDiM5TcR8gAE47BqAFdRSW1sMf6DndV0049kFEZyM+//TugKAuEAzq8GtBWE1KTD/rxRefx969u6FpARw/XogBAwYCAG66aRamT7/hjK+/445b8Le/vRvTMhIRNWGAnEHob/RzcL3R//k/jwIAiotP4IEH7utwGDA8iOhcYoCcSWOCiHORIO2YOTMXF188AocOfY+XX34Na9e+h507/4na2lqkp6fjmWeWIzU1DVddNQafffY1Xn/9VZSXl6GwsAAlJSeRkzMDc+fe3WXlJ6KeiQHSwud7i/HZnuKwfUII+AJBmEwKlLMYM7jqkl4YP7JX1K8fO3YcnnlmOY4fL0RBwVH85S9vQJZlPPvsk9i8+UPMnn1b2PmHDx/Cyy+/hvr6Otx8843Iy7sZDocj6s8nIjoVA+RMmjJDtHjeBS6+eAQAoE+fvviXf5mP/Pz1KCg4hu++24vs7D6tzr/ssjEwmUxISUlFUlISGhrqGSBE1KkYIC2MH9m6laAFdRwvrYcrJQGJVlMXlQywWCwAgIMHD+Bf//VxzJp1C6655looigwhWnevmc3m0HNJkto8h4jobHAa7xk09Vp1l9+/u3btxKWXXo4bb5yJvn37Yfv2z3rYEitEdL5gC+QMpMZ+q26SH7j22uuxaNECzJnzawDA0KEXobj4RBeXiojikSTiqG+joqK+1Tr4J08eQ1ZW/3ZfowuBgpN1SEu2wmEzt3ve+ep09Xe5HCgrqzvHJep68Vhv1jl+dKTesiwhLc3e/vHOKlRP1XIMnYiImjFAzqBpuY/4aacREUWGARIJzmIiImqFARIBLjlIRNQaAyQCksQuLCKiUzFAItSVa2EREXVHDJAIGFdyd3UpiIi6F15IGAEJ52Ya79neD6S+vh5Ll/4rli9fEeuiEhExQCIi4ZwMgpzt/UDq6mpx6ND3sSgaEVErDJAWAj98jsD3W1vtTwwEIUsS3Gr0PX6moRNhGjK+w687frwQK1YsR21tDSwWK+bPX4AhQ4Zhy5ZNePfdf4csy+jduzeeeOJZrFr1R5SXl+Gxx/7AVggRxRzHQCIiddkQ+tKlT+F3v3sQb7zxDh555HE89dQiAMBf//oKVq78M95442306pWNgoKj+P3vFyA93cXwIKJzIqYtkPz8fLzyyivQNA1z587FrbfeGnb8wIEDePzxx9HQ0IAxY8bg6aefhqqq2LlzJ5YvX45AIACn04lly5YhOzsbtbW1+MMf/oDCwkKkpqZi1apVcLlcnVZe05DxbbYSqssboCgSnCm2TvusSLjdbhw4sB/Llj0T2ufxeFBTU43x4yfgt7+9GxMnXo1Jk36BCy8cykUVieicilkLpKSkBCtXrsS7776L9evXY82aNTh8+HDYOQsWLMCTTz6JzZs3QwiBtWvXhvYvWbIEGzZsQG5uLpYsWQIAWLVqFcaMGYMPP/wQN910E5YuXRqr4oeRztUo+il0XYfZbMHf/vZu6PH//t/fkJSUjN///g9YsuQFOBxJePbZJ7B588ZzX0AiimsxC5Dt27dj7NixcDqdsNlsmDx5MjZt2hQ6XlRUBK/Xi9GjRwMA8vLysGnTJvj9fjz00EMYNmwYAGDo0KEoLjZuM/vpp58iNzcXAJCTk4OtW7ciEAjEqgohXZQfsNvt6NOnbygc/vnPL3D//fciGAxi1qxfwul04vbb78SUKdPxww/fQ1EUBIPBLigpEcWjmAVIaWlpWPdSRkYGSkpK2j3ucrlQUlICs9mMGTNmADD+Av/zn/+M6667rtVrVFWF3W5HZWVlrKrQrAuvA3nqqSXIz1+PuXNn4S9/eQnPPLMMqqri7rvvw+9/fz/uvvt2fPfdXtx221ykpqYhMzMLDzxwX9cUlojiSszGQHRdD61kCwBCiLDtMx33+/1YuHAhNE3Dffe1/QtRCAFZjjwD21rXvrRUhnqG2VWyLEEL6mc8r7P07dsH69f/NwBg0KCB+MtfXmt1ztSp0zB16rRW+1977W8d+ixZluFytX+v9NMd68nisd6sc/zorHrHLECysrLw9ddfh7bLysqQkZERdrysrCy0XV5eHjre0NCA3/72t3A6nXjllVdgMhn3Is/IyEB5eTmysrKgaRoaGhrgdDojLlNbN5TSdR2adoZbwgoBCJz5vPOQruvt3lyGN9yJH6xz/Dgvbig1btw47NixA5WVlfB4PNiyZQsmTpwYOp6dnQ2LxYKdO3cCADZs2BA6vmDBAvTv3x+rVq2C2dx8F8BJkyZh/fr1AICNGzdizJgxoXCJLS5lQkR0qpi1QDIzMzF//nzMmTMHgUAAM2fOxCWXXIJ77rkHDz74IEaOHIkVK1Zg8eLFqK+vx/DhwzFnzhzs378fH3/8MQYPHoxf/vKXAIyWx1//+lc89NBDWLhwIaZPnw6Hw4EVKzrneodTu89OJUk9czFF3uOEiM5G3N8TvbT0OFJTM6Gq7bdkyqs98PqD6JPRflPufKRpAVRWliAjo0+bx9nEjx+sc/w4L7qwzhcJCXbU1VVDiNOMb0g9757oQuioq6tCQkLPCkUiOnfifi0suz0ZVVVlKCk5jvZiot4TgD+g46RuObeFiykJZrMVdntyVxeEiM5TcR8gkiQhNTXjtOf8/eND2LanGC/Nn3SOSkVE1P3FfRdWJBRZghbsaZ1YRERnhwESAUWREAz2vGtAiIjOBgMkAqosQxdoNYOLiCieMUAioCjGNSJBna0QIqImDJAIKI3rbXEchIioGQMkAorc1AJhgBARNWGAREBt6sLiQDoRUQgDJAKKYvwzsQVCRNSMARKBpi4sjQFCRBTCAImAwi4sIqJWGCARUBtnYQU5C4uIKIQBEgHOwiIiao0BEoGmLiyNFxISEYUwQCIQmoXFLiwiohAGSARUmYPoRESnYoBEoGkpE46BEBE1Y4BEoHkMhAFCRNSEARIBhV1YREStMEAiwKVMiIhaY4BEoHkQnQFCRNSEARIBXgdCRNQaAyQCCpcyISJqhQESgeZb2jJAiIiaMEAi0LyYIruwiIiaMEAiwOtAiIhaY4BEgNeBEBG1xgCJAJdzJyJqjQESAUmSoCoSA4SIqAUGSIQURYbGLiwiohAGSIRUWeJ1IERELTBAIqQoMruwiIhaYIBESGUXFhFRGAZIhDiITkQUjgESIXZhERGFY4BESFVkXkhIRNRCTAMkPz8f06ZNw/XXX4933nmn1fEDBw4gLy8PkydPxuOPPw5N08KOr1q1CqtXrw5tf/XVV7jiiiswY8YMzJgxA4899lgsix9GVSRonIVFRBQSswApKSnBypUr8e6772L9+vVYs2YNDh8+HHbOggUL8OSTT2Lz5s0QQmDt2rUAgLq6OixatAhvvvlm2Pn79u3DXXfdhQ0bNmDDhg1Yvnx5rIrfCruwiIjCxSxAtm/fjrFjx8LpdMJms2Hy5MnYtGlT6HhRURG8Xi9Gjx4NAMjLywsd//jjjzFgwADceeedYe+5d+9efPbZZ8jNzcW8efNQXFwcq+K3osoSgryhFBFRSMwCpLS0FC6XK7SdkZGBkpKSdo+7XK7Q8RtvvBH33nsvFEUJe0+Hw4Hbb78d+fn5mDRpEubPnx+r4reiqjK7sIiIWlBj9ca6rkOSpNC2ECJs+0zH2/LMM8+Ens+ePRsvvvgi6urq4HA4IipTWpo90uK3osoyNFmHyxXZZ/UU8VbfJvFYb9Y5fnRWvWMWIFlZWfj6669D22VlZcjIyAg7XlZWFtouLy8PO34qXdfx6quvtmqZnNpKOZ2KinroUY5jKIoEr09DWVldVK8/H7lcjriqb5N4rDfrHD86Um9Zlk77h3fMurDGjRuHHTt2oLKyEh6PB1u2bMHEiRNDx7Ozs2GxWLBz504AwIYNG8KOtyqoLOOjjz7C5s2bAQDr16/HqFGjYLPZYlWFMCoH0YmIwsQsQDIzMzF//nzMmTMHN954I3JycnDJJZfgnnvuwd69ewEAK1aswPLlyzFlyhS43W7MmTPntO/5/PPP49///d8xffp0rFu3DkuWLIlV8VvhUiZEROEkIUTc/Fl9Nl1Yf9v8PQ4ercRz913ZyaXqvtjEjx+sc/w4L7qwehrjSvS4yVoiojNigETIGANhFxYRURMGSIQULmVCRBSGARIhzsIiIgrHAIkQu7CIiMIxQCKkKrwnOhFRSwyQCCmy0YUVR7OeiYhOiwESIVUx1uniOAgRkYEBEiFVMf6pGCBERAYGSISUpgDhciZERAAYIBFr6sLS2AIhIgLAAIlYcwuEAUJEBDBAImZqGkRnFxYREYAIA6S8vBwff/wxAOCPf/wj5s6di4MHD8a0YN2NwkF0IqIwEQXIwoULUVhYiB07dmDbtm2YMWPGOb0XR3egysY/FcdAiIgMEQVIdXU17rjjDmzduhU5OTnIy8uDx+OJddm6FVVlFxYRUUsRBUggEEAgEMC2bdswbtw4eDweuN3uWJetW2EXFhFRuIgC5Nprr8WVV16JlJQUjBgxAjfddBNycnJiXbZupakLi7OwiIgMaiQnPfjgg7j55puRmZkJwLiX+bBhw2JasO5GCS1lwi4sIiKgA7OwvvvuO0iShD/+8Y9Yvnx53M3CalrKhDeVIiIycBZWhFS2QIiIwnAWVoR4JToRUTjOwoqQibOwiIjCcBZWhJoG0TVeB0JEBKCDs7CysrIAxOcsLN4PhIgoXEQBous68vPzsXXrVmiahvHjx2Pw4MFQ1Yhe3iMoMgOEiKiliLqwXnzxRXzxxReYO3cu7rzzTnz77bd44YUXYl22boVLmRARhYuoCbFt2zasW7cOJpMJAHD11VfjhhtuwKJFi2JauO6E14EQEYWLqAUihAiFBwCYzeaw7XigyE3XgTBAiIiACANk2LBhWLZsGQoKClBYWIjly5djyJAhsS5bt2JSm8ZA2IVFRAREGCBPPfUUamtrMWvWLNx8882oqKjA7NmzY122bqVpEJ1dWEREhojGQOx2O5577rmwfZdddhm++eabmBSqO5JlCZLEFggRUZOo74kuRPz9Ja7IMpcyISJqFHWASJLUmeU4L6iKxEF0IqJGUQdIPFJkiUuZEBE1Ou0YyKWXXtpmS0MIAa/XG7NCdVeKIrMFQkTU6LQB8sEHH5yrcpwXVEXiGAgRUaPTBkh2dva5Ksd5QZElaJyFRUQEgGMgHcJZWEREzWIaIPn5+Zg2bRquv/56vPPOO62OHzhwAHl5eZg8eTIef/xxaJoWdnzVqlVYvXp1aLu2thb33nsvpk6diltvvRVlZWWxLH4rCmdhERGFxCxASkpKsHLlSrz77rtYv3491qxZg8OHD4eds2DBAjz55JPYvHkzhBBYu3YtAKCurg6LFi3Cm2++GXb+qlWrMGbMGHz44Ye46aabsHTp0lgVv02qLHM1XiKiRjELkO3bt2Ps2LFwOp2w2WyYPHkyNm3aFDpeVFQEr9eL0aNHAwDy8vJCxz/++GMMGDAAd955Z9h7fvrpp8jNzQUA5OTkYOvWrQgEArGqQiuKIkFjC4SICECES5lEo7S0FC6XK7SdkZGBPXv2tHvc5XKhpKQEAHDjjTcCQFj31amvUVUVdrsdlZWVyMzMjKhMaWn2qOrSxGpRoSgyXC7HWb3P+SSe6tpSPNabdY4fnVXvmAWIruth15AIIcK2z3Q8EkIIyHLkjaiKinroUbYgXC4H9KAOTyCIsrK6qN7jfONyOeKmri3FY71Z5/jRkXrLsnTaP7xj1oWVlZUVNshdVlaGjIyMdo+Xl5eHHW9LRkYGysvLAQCapqGhoQFOp7NzC34aqiJzNV4iokYxC5Bx48Zhx44dqKyshMfjwZYtWzBx4sTQ8ezsbFgsFuzcuRMAsGHDhrDjbZk0aRLWr18PANi4cSPGjBlzTm9spcgSV+MlImoUswDJzMzE/PnzMWfOHNx4443IycnBJZdcgnvuuQd79+4FAKxYsQLLly/HlClT4Ha7MWfOnNO+50MPPYRdu3Zh+vTpePfdd/Hkk0/Gqvht4lImRETNJBFH67Kf7RjIs6/tQEFJPZbdO7aTS9Y9sY84frDO8eO8GAPpibgaLxFRMwZIBygyu7CIiJowQDqAS5kQETVjgHQAlzIhImrGAOkALmVCRNSMAdIBiswbShERNWGAdIBxHQi7sIiIAAZIh6iyBCEQ9bUkREQ9CQOkAxTFWOyRrRAiIgZIhyiNK/9yQUUiIgZIhzS3QBggREQMkA5Q5cYA4bUgREQMkI5QFOOfiy0QIiIGSIcojS0QXkxIRMQA6ZDQGAi7sIiIGCAdoTbOwuLV6EREDJAOaerC4hgIEREDpEOaBtE1XkhIRMQA6YjmMRC2QIiIGCAdwOtAiIiaMUA6gNeBEBE1Y4B0QOg6EHZhERExQDqieRYWu7CIiBggHcAuLCKiZgyQDjA1zsJy+7QuLgkRUddjgHRAenIC0pOt+HxvcVcXhYioyzFAOkCWJUz+eT/8WFSLQ8eru7o4RERdigHSQVeN7IVEq4pNXxZ0dVGIiLoUA6SDLGYF11zWB7sOlaO4oqGri0NE1GUYIFG49vI+UBQZW/5Z2NVFISLqMgyQKCQnmjF+ZBY+33sSNQ3+ri4OEVGXYIBE6fqf9UVQ1/HaB/vhCwS7ujhEROccAyRKvdISccfUYdh/pBL/9z93w+vntSFEFF8YIGdhwiW9cU/uxfihsAZ/WrMbbi9DhIjiBwPkLI0dnoV5M4bjSHEt/vXNr/B9QVVXF4mI6JxggHSCMcMy8Ogtl0GSgBfe/RZrPzmMgMZxESLq2RggZyCEQPDkIQhx+gUUB/dJxtN3/RyTRvfGpq8K8OhfdmDzVwUcGyGiHosBcgaioRLu/1qKhv2fnfFcq1nFnCnDsGD2pchKtWHNJ4ex4OXtWPe/P6Kkyn0OSktEdO6osXzz/Px8vPLKK9A0DXPnzsWtt94advzAgQN4/PHH0dDQgDFjxuDpp5+Gqqo4ceIEFixYgIqKClxwwQVYsWIFEhMT8dVXX+GBBx5AVlYWAODiiy/G8uXLY1kFSIkpkBKS0PDDPyFnjI7oNRf1T8FF/VPwY1ENNn5xDBu/OIb/3nEMQ/s6MXZ4JkYOTENqkjWm5SYiijVJnKlvJkolJSWYPXs23n//fZjNZsyaNQt/+tOfMHjw4NA5OTk5WLJkCUaPHo1FixZhxIgRuOWWW3DffffhhhtuwPTp0/HSSy/B7XZjwYIFeOONNxAIBHDfffdFVaaKinroUdzLw/u/ryN4dCdst/8bJLnjmVtV58P2fcXYtqcYpVUeAEB2eiIuHpCKof2cGNLXCXuCqcPvG2sulwNlZXVdXYxzLh7rzTrHj47UW5YlpKXZ2z/eWYU61fbt2zF27Fg4nU7YbDZMnjwZmzZtCh0vKiqC1+vF6NGjAQB5eXnYtGkTAoEA/vnPf2Ly5Mlh+wFg7969+Oyzz5Cbm4t58+ahuPjcLKuu9BsN3edG8OShqF6f4rBg+pUDsPzesXj27p/j5msGIynRjH98W4Q/v78XD/7fbVj82pf4a/532PJVAQ4eq0K9J9DJtSAi6lwx68IqLS2Fy+UKbWdkZGDPnj3tHne5XCgpKUFVVRXsdjtUVQ3bDwAOhwNTp07F9ddfj/feew/z58/H3//+91hVIUTtMxxQVGjHdkHtfVHU7yNJErJddmS77JhyRT8ENB1HimvxfWE1fiqqwcGCauz4riR0frLdjOz0RPRKS0TvNBuyUm1wOROQkmSBInP4ioi6VswCRNd1SJIU2hZChG23d/zU8wCEtp955pnQvtmzZ+PFF19EXV0dHA5HRGU6XVPs9BwI9h8BrWgPXK57o3yPtvXulYzxl/UNbVfVeXHkRC2OFdfiaHEtCk7W4vO9xfD6m6cFy7KE9GQrXCk2ZKba4EpJQGaKDZlpNmSk2JCaZIXZpHRK+VyuyP5te5p4rDfrHD86q94xC5CsrCx8/fXXoe2ysjJkZGSEHS8rKwttl5eXIyMjA6mpqairq0MwGISiKKHX6bqOV199Fffeey8UpfmXY8vnZxLtGAgA2C4cg4rNr6Hk0CHIzqyo3iNSfVMT0Dc1AVcNzwRghGtVnQ/FlW5U1HhRXuNFeY0HFTVe7PqhFFV1Ppw6kpVoVZFst8CeYGp8qEhOtCA1yYLUJCuSbGYkJqiwJ5hgMSmtQhtgH3E8YZ3jR2eOgcQsQMaNG4fVq1ejsrISCQkJ2LJlC5599tnQ8ezsbFgsFuzcuROXX345NmzYgIkTJ8JkMmHMmDHYuHEjcnNzsX79ekycOBGyLOOjjz5C//79MW3aNKxfvx6jRo2CzWaLVRXC2AZfjorNr0Er+BZm59Rz8plNJElCapK13ZlbWlBHZZ0PFdUelNd4Ud3gR029DzUNftS7AyipdOOwJ4C6Bj/aik9FlpBoVZFgNcFuVZGYYEKi1QRXqg3QdSRYVNisKhw2M5JsZtgTVCRYjIeqsCuNKF7FbBYWYEzjffXVVxEIBDBz5kzcc889uOeee/Dggw9i5MiROHjwIBYvXoz6+noMHz4cy5cvh9lsRlFRERYuXIiKigr06tULf/rTn5CcnIxDhw7hiSeeQF1dHVJTU/HCCy+gV69eEZfnbFogLpcDR19+CJLVDlvuwqjeo6tpQR019X5U1nlR5w6g3mM8GrwBeLwaGrwaGrwBNHg01HsC8Pi1M67vZTbJsFlUJFpNsFmNr/YE43mCRYXFpMBqVmBSZeOhyEZANbaMbBYVJrV7hVA8/mXKOsePzmyBxDRAupuzDZDj//0m/Ls3wj5nNSRLYieXrvtxuRwoKa2F1xdEvTeAOrcfde4AGjwBuH0aPD4jYNw+rTGAAmjwaqFQ8gf0iD5HVWTYLEqoVdMyeCxmxWj9JJjhsJlgNauwmIwwspqNlpHNqiLBrEKWW3fDRVvvePvFwjrHj/OiC6snUvuPhn/XB3DnPwfThVdCHXQFZHtaVxcrpmRJCv2SznAmdOi1ui7g9QfhCwQR0IIIBAX8gSDcjSFTf0oQef0aPL4gPD7juM8fhDcQhNsbgBY8c/BbzUYI2SwqrJbm503jQIkJJthbtJSMrypsVlO3awURnQ8YIB0gZwyCZcIdCBz8X/i+XAvfl2sh2dMgO3sZD3saJJsTki0ZkjUJksUGyZIISTV3ddG7hCw3h8/ZEMIIojq3H15/EH5Nhz8QhM8fRENjC8jtDcDjC8LtC4RCqMETQFmVxwgqr9bm+E8Tq1mBw2aCw2ZGmjMBFkWG3WZCks2MZLsZyYlmJCU2jQGZOq21Q3Q+Y4B0gCRJMF90NcwXXQ29pgSBIzuhVxZCry5G4OBWQPO1/UJZAUxWSCYrJJMFUC1GqKhm48p2RQVkFZJiMp4rJkiN+6Coxjmy0nieAklWjO3GhyQrgNS4LcktzpEb9ymQZLnxHDl0ntTifMiysU/qfn+JS5IU6tqKlq4LNHiNIKlvHOdx+4yxn3qvhjq3MeGg1u1HRbUXVXVe1Ln9bbZ8JAlw2i1IcViQ6jBmtTV9TUmyINVhRXKimSFDPR4DJEpyciYso6eFtoUQgN8N3V0N4a6B8NZD+BogfA1AwAPh90IEvIDmg9B8gOY3ztE1IKhBBDUgGDCe643P9S5YEl6SQmHUoCgQUsuQaQomtTmITg00qXE7FHZq6LkRkk3BqECSTYCiGIEpG8EZCkzVZASqaj4lWI19kNU2px63R5YlOGxmOGxmZJ7h3KY+YiEEPD4NNQ1+1Db4UesOoLbBj5oGH6rqfKis9aGwrAF7fqpoNd6jyBJSHBa4nAlwOa1wOROQkWJDhjMBGSkJZxWGRN0Ff4o7iSRJgCURiiURSMnulPcUQgeCmhEketAIlsbnxnbzcwi9eVvogK41buuN222dY+wXTcdD+419CRYZngZv689q2hYttjV/2LGwsoZCMQjoAbS6aCUqkhEuTS051Wy07Fq28EwWSKoFkslqPDdZIZkSAHMCpMaH8dxmPE7papQkCTarCTarCb3S2p80IYRAg1dDZa0XlXU+VDV+rajxoqzGg12HylHrDl+aJtluRq9UG7LSEpGdnog+rkRku+zdck00ovYwQLoxSZKNv7abts/x56fHaJaK0I2AQzBgBFEwYDwPBpv3BwOAFoAI+ptbZi33af7Gbb8RXpoPIuAzvnpqITQfhOYPtfoQjOC+LIoKyWKHz56MoCnRGMey2psfCcmQbMmQbU7juckCwAiapoH6fpltX+Hr9WsorfKgtMqDkio3TlYajy/3l8Djay6b025GtsuOPq5E9M2wo1+GA1lpNl5vQ90SA4TOOUmWAbmx5XCOPlPoGtDYjSgCHgi/B/C7IfweCJ8bwu+G8LkBXwNU4YFWUwW97CcIbx3g97T9piYrJJsTcmIKpMRU46s9FbI93Zhc4UgPhYzVrKJfpqNVwDStMnC8rAFFZfUoKm/A8bJ6fLyzGlrQ6BZTFRkDejkwODsZF2Yn48JuunozxR8GCMUFSVaBxpbEmZw6T17oQWO8ylML4amBcFc3j3W5q6E3VEEvPgitodro1mv5uQlJkBwuyEkZkJMzGx/GrD3JZAlbZeCSQc1TwoO6jpOVHhSW1OHoyTr8eKIG//N1ITZ9WQAJQJ8MO4b2c2LEBWkY1s/ZaWufEXUEA4ToDCRZgWRLBmzJAPq2e57QdSNg6sqh11dAryuHqCuFXluG4MkfoB3+AmgxmViyp0FOyYackg0ltQ/k1D6QU3pDUkxQZBnZ6cb4yNjhxtprAS2II8V1+L6wGt8XVGHrrhP4n6+Pw6TKuKh/CkZckIoRA9OQmZLQoQkGRNFigBB1EkmWISWmAIkpUHBhq+NC80OvLYNefQJ6dbHxtbIIgaL9COiN4yCyAjmlD5T0/pBdA6C4BkJO7QNJUWFSFQzpa9yALHfcAAS0IL4vqMaeHyuw56cK7PmxAsAhpCdbMXJgGkYOSsNF/VJgMbN1QrHBACE6RyTVDCU1G0pq+Cw9oQeh15ZAryiEXn4MwYoCBI7uBL7fapygqFBcA6FkDoaSNQRK72GQTFaYVAUjBqZhxMA03AKgtNqD736qwL4jldi+7yT+8W0RVEXGsH5OjBqcjksGpcHVwdUEiE6Ha2FFKB7XzYnHOgPdo95CCIi6cgTLjiBY+iOCJYeglx8zpkUrKpTeF0HtNwpqv1GQHa5Wrw9oOg4dN1onu3+sQEmlGwDQOz0RowenY/TgdAzsnRS62LE71Plci8c6A1xMMWoMkI6JxzoD3bfeQvMjWHIYWsFuaAW7IWpOAgDklN5Q+o6C2n80lMzBxoWcpyipdGP34XLs/rECPxRWI6gLOGwmXDIwDaMGp2PSz/qhoc57rqvUpbrr9znWGCBRYoB0TDzWGTh/6q1XnzTCpHA3gie+N2aAmW1Q+46E2n801L6XtLlqtNsbwN6fKrH7cDn2/FgBt08L6+oaNTgN6ck9v6vrfPk+dzYGSJQYIB0Tj3UGzs96C78H2vF90Ap2I1i4B8JTC0gylKwLofa/DOqAyyAnte7q0oI6Dh+vwQ8narFjzwmUVBnXvPRxJRphMii8q6snOR+/z52BARIlBkjHxGOdgfO/3kLo0Et/gnZsF7Rju6BXHQcAyGl9jTC54HLIqX3Dpvo21bm4ogG7D1dgz4/lOHS8BkFdwJ5gwsiBaRg1OA0X9U+Bw9YzVpc+37/P0WKARIkB0jHxWGeg59Vbry2FdvQbaEe/QfDkIQACksMFdYDRMlEyL0RGZnKrOru9Aew70tzV1eDVIAHol+nAxQNScFH/FFzYx3neThPuad/nSDFAosQA6Zh4rDPQs+ute2qhHfsW2pGdCBbtB3QNUkIS7EN/Di1zBJTsi9u8f01Q13GkuA4HjlZi/9EqHC4yWieKLOGC3km4MDsZg7OTMSg7GUmJ50cLpSd/n0+HARIlBkjHxGOdgfipt/B7oBXuMcLk+F5jfTDVDLXPCKj9L4XSbxTkhKQ2X+sLBHH4eA0OHKvC9wVVOHqyDsHG/1upSRb0z3Sgf5YDfV12ZGfYkZ5shdzNro6Pl+/zqXhLWyI6a5I5AaZBV8A06Aqkp1hxcu/XRlfXsV3Qjn4DQIKcMdAIlL4jIbsuCE0RtpgUDL8gFcMvSAVgLLNy9GQdfiyqxbHG9bu+PVQe+iyLSUHvdBt6pyWid3oiXM4EpCVbkZZkhcNm4tIr5ym2QCIUj3+txGOdgfisd8s6CyGgVxQYXV2Fe6CXHgEgAHMC1N4XQ+kzHGr2cEhJGaf9xe/xaTjRuLrw8bIGnChvwImKBtTU+8POUxUZqQ7jDo/JdjMcCebG2wsbtxi2J5hCt0Y27nevdkprJh6/zwBbIEQUQ5IkQUnvDyW9PyyX3wjhrYdWtB/B4/ugFX0H7ehO+ABINqextEqvIVAyBofW7GqSYFExqHFcpCW3N4DyGi8qarwor/WiqtaHyjrjJlxHT9ahzh0Iu0dKWyxmBQlmBVazCqtZgdWswGxSYFJl46HIMJsUmJu2VRkmVYFJkaA2Hk9NrYO7wQeTIkNVJKiKbDzUxm3Z+CrLEhTZ+KoqMhRZYoupEQOEiE5LstphGvRzmAb93FhipaYE2on9CBb/gODJ76H99JVxoqJCTjOCR07rByWtL2Rnb+POjy3YrCb0s7Z/8y3AuD6l3hNAvTuAOrcfDV4NHp/xcPs0eP1BY9sfhM8fhC8QRE29H1pQh18Lwq/pCAR0+DU9dF+VzqTIEhRFgnJqyEjNz5tCR5HlU7Zbny/LEmQJkCUJUuNzSWpxXJKgKhIURYYqN58jS0aYKS3eQ5Ik487UodcDIwamISkG068ZIEQUMUmSIDmzYHZmARf/wgiU+goEy35CsPQn6GVHEDi0A9j/SfNrElMgO3tDTnIZ90ZxuCDbUyElpkCyOdtcekVVZDjtFjjtlrMusy4ENE1HIKgjoOmh546kBJSV1xv7gjq0oGj82rwdDOoI6gK6LhAUAsHGc4J683NNF9B1HboO41whml8T1EOvC+oCgaAOr984povGc1o8F0JAFwj/2nhcCxr1iKYTPnfcAPxy4sCz/rc8FQOEiKImSRIkRzpkRzpMA38OoMVCkJUF0KuKQ0vXaz99DeGrP/Udmm8XnOCAZHVAsiQ2PmyA2Wbcy95sBVRr4/3tzZBUC6CYjCnHigpISrvdSrIkGd1Zp9x0y+VywG46/24V3BQoRrgYAdkUWqJF6ISeA0hPtsakLAwQIupUkiRBSnIZS6cMCD8m/B7odWUQDZXQG6ohGqqMm3B56qB7aiAqCiB8DRC+BkB0oOtJkgDZZNzXXlEBWQVkxWjdyCogy4CsAJLcuE9BscUMv6YDkBr3y4DU+JBlY78sQ5Ian0tND7n5a4v9xnloPt7yuSSFvweaxlHaOobGbYR/RmM9pRbbsiRBPuV46PVN25IEyXoxEMHdODuKAUJE54xkToCS1g9I63fa84QQgOYz7lnvdwMBH0TAa3zVfIDmh9D8QNAPEdSAYAAiGDCWuw8GIIJBQNeMbT0ICB2ixXPoQeh+D4RfM7aFDtH0Vddh/PmuNz5E81cIQIjGc0Wbx8KeR9Xh1PnMo3Ng+fnMTn9fBggRdTuSJAGmxi6rxJSYfMa5msYrWgZNy2AROGUfjHA6ZbvdYBJAKKBEi9eg6T2aj8vJvWJSNwYIEVEMSaGuqcjGW86nCcLn3wgSERF1CwwQIiKKCgOEiIiiwgAhIqKoMECIiCgqDBAiIopKXE3jleWzmyB3tq8/H8VjnYH4rDfrHD8irfeZzour+4EQEVHnYRcWERFFhQFCRERRYYAQEVFUGCBERBQVBggREUWFAUJERFFhgBARUVQYIEREFBUGCBERRYUBcgb5+fmYNm0arr/+erzzzjtdXZyY+fOf/4zp06dj+vTpeOGFFwAA27dvR25uLq6//nqsXLmyi0sYW88//zwWLlwIoOfX+5NPPkFeXh6mTp2KJUuWAOj5dQaADRs2hH7Gn3/+eQA9t9719fXIycnB8ePHAbRfzwMHDiAvLw+TJ0/G448/Dk3TOvZBgtp18uRJcc0114iqqirR0NAgcnNzxaFDh7q6WJ3u888/F7/+9a+Fz+cTfr9fzJkzR+Tn54tJkyaJgoICEQgExF133SU+/fTTri5qTGzfvl1cccUV4tFHHxUej6dH17ugoEBcddVVori4WPj9fjF79mzx6aef9ug6CyGE2+0WP/vZz0RFRYUIBAJi5syZ4uOPP+6R9d61a5fIyckRw4cPF4WFhaf9mZ4+fbr49ttvhRBCPPbYY+Kdd97p0GexBXIa27dvx9ixY+F0OmGz2TB58mRs2rSpq4vV6VwuFxYuXAiz2QyTyYRBgwbh6NGj6N+/P/r27QtVVZGbm9sj615dXY2VK1di3rx5AIA9e/b06Hp/9NFHmDZtGrKysmAymbBy5UokJCT06DoDQDAYhK7r8Hg80DQNmqbBbrf3yHqvXbsWTz31FDIyMgC0/zNdVFQEr9eL0aNHAwDy8vI6XP+4Wo23o0pLS+FyuULbGRkZ2LNnTxeWKDYuvPDC0POjR4/iww8/xG233daq7iUlJV1RvJh68sknMX/+fBQXFwNo+3vek+p97NgxmEwmzJs3D8XFxbj66qtx4YUX9ug6A4DdbsdDDz2EqVOnIiEhAT/72c967Pd66dKlYdvt1fPU/S6Xq8P1ZwvkNHRdhyQ1L2cshAjb7mkOHTqEu+66C4888gj69u3b4+v+n//5n+jVqxeuvPLK0L6e/j0PBoPYsWMHli1bhjVr1mDPnj0oLCzs0XUGgIMHD2LdunX4xz/+gW3btkGWZRw9erTH1xto/2e6M37W2QI5jaysLHz99deh7bKyslCzsKfZuXMnHnzwQSxatAjTp0/HV199hbKystDxnlj3jRs3oqysDDNmzEBNTQ3cbjeKioqgKEronJ5W7/T0dFx55ZVITU0FAFx33XXYtGlTj64zAHz22We48sorkZaWBsDornn99dd7fL0B4/dYW/+XT91fXl7e4fqzBXIa48aNw44dO1BZWQmPx4MtW7Zg4sSJXV2sTldcXIz7778fK1aswPTp0wEAo0aNwpEjR3Ds2DEEg0F88MEHPa7ub775Jj744ANs2LABDz74IH7xi1/gtdde69H1vuaaa/DZZ5+htrYWwWAQ27Ztw5QpU3p0nQFg2LBh2L59O9xuN4QQ+OSTT+LiZxxo//9ydnY2LBYLdu7cCcCYpdbR+rMFchqZmZmYP38+5syZg0AggJkzZ+KSSy7p6mJ1utdffx0+nw/PPfdcaN+sWbPw3HPP4YEHHoDP58OkSZMwZcqULizluWGxWHp0vUeNGoXf/OY3uOWWWxAIBDB+/HjMnj0bAwcO7LF1BoCrrroK+/fvR15eHkwmE0aOHIkHHngA48eP79H1Bk7/M71ixQosXrwY9fX1GD58OObMmdOh9+YdCYmIKCrswiIioqgwQIiIKCoMECIiigoDhIiIosIAISKiqHAaL1EnGDp0KIYMGQJZDv+b7KWXXkKfPn06/bN27NgRuhiQqKswQIg6yVtvvcVf6hRXGCBEMfbll19ixYoV6N27N3766SdYrVY899xzGDRoEOrq6vD000/j4MGDkCQJEyZMwMMPPwxVVbF7924sWbIEHo8HJpMJjzzySGjdrtWrV2P37t2orq7G3XffjVtvvbWLa0nxiAFC1Enmzp0b1oXVp08fvPTSSwCAffv24dFHH8WYMWPw3nvvYcGCBXj//fexZMkSOJ1O5OfnIxAI4Le//S3eeOMN3Hnnnbj//vuxZMkSXH311di3bx8ee+wxbNiwAQDQt29fPPXUU9i/fz9+/etf4+abb4bJZOqSelP8YoAQdZLTdWENGzYMY8aMAQD86le/wjPPPIOqqips3boV7733HiRJgtlsxqxZs/DWW29h/PjxkGUZV199NQBgxIgRyM/PD71fTk4OAOCiiy6C3+9HfX09UlJSYltBolNwFhbROdBy1deW+05dUlvXdWiaBkVRWi2t/cMPP4RuOaqqxt9+TedwRSLqCgwQonPg4MGDOHjwIABgzZo1uPTSS5GUlISrrroKb7/9NoQQ8Pv9WLt2LcaNG4eBAwdCkiR8/vnnAIDvvvsOc+fOha7rXVkNojDswiLqJKeOgQDAww8/DKvVivT0dKxatQpFRUVITU3FCy+8AABYvHgxlixZgtzcXAQCAUyYMAHz5s2D2WzG6tWrsWzZMrzwwgswmUxYvXo1zGZzV1SNqE1cjZcoxr788ks8++yz+OCDD7q6KESdil1YREQUFbZAiIgoKmyBEBFRVBggREQUFQYIERFFhQFCRERRYYAQEVFUGCBERBSV/w/ye7Q0QLut+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train model\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10, restore_best_weights=True)\n",
    "history = autoencoder.fit(x=train_set, y=train_set, epochs=100, verbose=1, validation_data=[test_set, test_set], callbacks=[es])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1e0af",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72e59e2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd593a6c200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd593a6c200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "train_predicted_x = autoencoder.predict(x=train_set)\n",
    "train_events_mse = losses.mean_squared_error(train_set, train_predicted_x)\n",
    "cut_off = np.percentile(train_events_mse, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a8e0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples = 492\n",
    "# normal event\n",
    "real_x = test_set[:plot_samples].values.reshape(plot_samples, n_features)\n",
    "predicted_x = autoencoder.predict(x=real_x)\n",
    "normal_events_mse = losses.mean_squared_error(real_x, predicted_x)\n",
    "normal_events_df = pd.DataFrame({\n",
    "'mse': normal_events_mse,\n",
    "'n': np.arange(0, plot_samples),\n",
    "'anomaly': np.zeros(plot_samples)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e1e59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abnormal event\n",
    "abnormal_x =df_fraud[:plot_samples].values.reshape(plot_samples, n_features)\n",
    "predicted_x = autoencoder.predict(x=abnormal_x)\n",
    "abnormal_events_mse = losses.mean_squared_error(abnormal_x, predicted_x)\n",
    "abnormal_events_df = pd.DataFrame({\n",
    "'mse': abnormal_events_mse,\n",
    "'n': np.arange(0, plot_samples),\n",
    "'anomaly': np.ones(plot_samples)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b84e4f4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.lines as lines\n",
    "mse_df = pd.concat([normal_events_df, abnormal_events_df])\n",
    "plot = sns.lineplot(x=mse_df.n, y=mse_df.mse, hue=mse_df.anomaly)\n",
    "\n",
    "line = lines.Line2D(\n",
    "xdata=np.arange(0, plot_samples),\n",
    "ydata=np.full(plot_samples, cut_off),\n",
    "color='#CC2B5E',\n",
    "linewidth=1.5,\n",
    "linestyle='dashed')\n",
    "\n",
    "plot.add_artist(line)\n",
    "plt.title('Threshlold: {threshold}'.format(threshold=cut_off))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e47424",
   "metadata": {},
   "source": [
    "### 3. Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60baa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c6949ad",
   "metadata": {},
   "source": [
    "# Week 5 (19 march – 2 april) \n",
    "9. Model performance\n",
    "\n",
    "10. Performance measures (RMSE, MAE,…) \n",
    "    \n",
    "11. Feature importance\n",
    "\n",
    "12. Evaluation of the results (Overfitting )\n",
    "\t\n",
    "13. Interpretation of the results  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4a5b4",
   "metadata": {},
   "source": [
    "### 1. Performance measure\n",
    "\n",
    "RMSE \n",
    "MAE\n",
    "(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "871e708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_abnormal = pd.DataFrame(abnormal_events_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fc13cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = []\n",
    "bad=[]\n",
    "def classify(mse, cutoff): \n",
    "    for row in mse_abnormal.itertuples(index=False):\n",
    "        if row >= cutoff:\n",
    "            count_good  =good.append(1)\n",
    "        else: \n",
    "            count_bad = bad.append(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf0d4455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of well classify abnormal transactions is:0.8414634146341463\n"
     ]
    }
   ],
   "source": [
    "classify(pd.DataFrame(abnormal_events_mse), cut_off)\n",
    "print('The ratio of well classify abnormal transactions is:{}'.format((len(good)/len(mse_abnormal))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa95a30",
   "metadata": {},
   "source": [
    "### 3. Evaluation of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5e5af",
   "metadata": {},
   "source": [
    "The ratio of well classify abnormal transactions is:84% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474b19b",
   "metadata": {},
   "source": [
    "### 4. Interpretation of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28328ffe",
   "metadata": {},
   "source": [
    "When looking at the graph above, we see that the model have larger MSE in most of the case when he is predicting on non-normal transactions. Which is exactly what we wants, as the goal of the autoencoders is to recreate those datapoints into the original form (what he has learn in the training) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b4afd",
   "metadata": {},
   "source": [
    "# Week 6 (2 april – 10 april) \n",
    "10. Develop presentation\n",
    "\n",
    "11. Wrapping up\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
